{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¥ç»ç½‘ç»œç›¸ä¼¼åº¦æµ‹é‡ç»¼è¿° (Survey of Neural Network Similarity Measures)\n",
    "\n",
    "**Based on:** Klabunde et al. (2025). \"Similarity of Neural Network Models: A Survey of Functional and Representational Measures\"\n",
    "\n",
    "**ä½œè€…æ•´ç† (Compiled by):** YueYueYYY\n",
    "\n",
    "**æ—¥æœŸ (Date):** 2025å¹´12æœˆ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ç›®å½• (Table of Contents)\n",
    "\n",
    "1. [è®ºæ–‡æ¦‚è¿° (Paper Overview)](#section1)\n",
    "2. [æ ¸å¿ƒæ¦‚å¿µ (Core Concepts)](#section2)\n",
    "3. [è¡¨ç¤ºç›¸ä¼¼åº¦æµ‹é‡ (Representational Similarity)](#section3)\n",
    "4. [å‡½æ•°ç›¸ä¼¼åº¦æµ‹é‡ (Functional Similarity)](#section4)\n",
    "5. [ä»£ç å®ç° (Code Implementation)](#section5)\n",
    "6. [ç”Ÿç‰©å­¦åº”ç”¨ç¤ºä¾‹ (Biological Applications)](#section6)\n",
    "7. [æ€»ç»“ä¸å±•æœ› (Summary)](#section7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Paper contents"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "2 Similarity of Neural Network Models\n",
    "\n",
    "2.1 Representational Similarity\n",
    "\n",
    "2.2 Functional Similarity Measures\n",
    "\n",
    "2.3 Relationship between Representational and Functional Similarity\n",
    "\n",
    "\n",
    "3 Representational Similarity Measures\n",
    "\n",
    "3.1 Canonical Correlation Analysis-based Measures\n",
    "\n",
    "3.2 Alignment-based Measures\n",
    "\n",
    "3.3 Representational Similarity Matrix-based Measures\n",
    "\n",
    "3.4 Neighborhood-based Measures\n",
    "\n",
    "3.5 Topology-based Measures\n",
    "\n",
    "3.6 Descriptive Statistics\n",
    "\n",
    "4  Functional Similarity Measures\n",
    "\n",
    "4.1 Performance-based Measures\n",
    "\n",
    "4.2 Hard Prediction-based Measures\n",
    "\n",
    "4.3 Soft Prediction-based Measures\n",
    "\n",
    "4.4 Gradient and Adversarial Example-based Measures\n",
    "\n",
    "4.5 Stitching-based Measures\n",
    "\n",
    "5 Properties and Application of Similarity Measures\n",
    "\n",
    "Properties and Evaluation of Similarity Measures.\n",
    "\n",
    "Resources\n",
    "\n",
    "Applications in the Literature.\n",
    "\n",
    "Similarity Measure Selection.\n",
    "\n",
    "Additional Practical Considerations.\n",
    "\n",
    "6 Discussion and Open Research Challenges\n",
    "\n",
    "Applicability of Representational Similarity Measures.\n",
    "\n",
    "Interpretability\n",
    "\n",
    "Robustness of Representational Similarity Measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Explaination-what is neural network?/How It Works"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "what is neural network?\n",
    "\n",
    "explain from the ground up, since this connects to your computational biology work.\n",
    "\n",
    "A neural network is a computational model inspired by how biological neurons in the brain work. It's essentially a mathematical function that learns patterns from data.\n",
    "\n",
    "Basic Structure\n",
    "Think of it like a processing pipeline with layers:\n",
    "Input â†’ Hidden Layer(s) â†’ Output\n",
    "Example from your field:\n",
    "\n",
    "Input: Gene expression levels, protein sequences, or histone modification data\n",
    "Hidden layers: Mathematical transformations that extract patterns\n",
    "éšè—å±‚ï¼šæå–æ¨¡å¼çš„æ•°å­¦è½¬æ¢\n",
    "Output: Prediction (e.g., \"toxic\" vs \"non-toxic\", or gene expression level)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How It Works\n",
    "\n",
    "Neurons (nodes): Each neuron receives inputs, applies a mathematical transformation, and passes the result forward\n",
    "Connections (weights): Each connection has a \"weight\" - a number that gets multiplied with the input. These weights are what the network \"learns\"\n",
    "\n",
    "Layers:\n",
    "\n",
    "Input layer: Your raw data\n",
    "Hidden layers: Where pattern extraction happens (this is what the paper calls \"representations\")\n",
    "Output layer: Final prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Simple Example\n",
    "For your RNA-seq work, imagine a network that predicts if a gene is differentially expressed:\n",
    "[Gene counts] â†’ [Hidden patterns] â†’ [Up/Down/No change]\n",
    "     â†“              â†“                      â†“\n",
    "  Input layer   Representation        Output\n",
    "The representations (middle layers) might capture biological patterns like:\n",
    "\n",
    "Co-expression modules\n",
    "Pathway activation states\n",
    "Cell type signatures"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Why This Paper Matters\n",
    "This survey is about comparing neural networks. When you train two models (even with the same architecture but different random starting points), they might:\n",
    "\n",
    "Learn similar representations (internal patterns)\n",
    "Give similar outputs (predictions)\n",
    "Or do both differently!\n",
    "\n",
    "The paper provides tools to measure and understand these similarities.\n",
    "\n",
    "Connection to Your Work\n",
    "\n",
    "You could use neural networks for:\n",
    "\n",
    "Predicting gene expression from sequence features\n",
    "Classifying cell types from RNA-seq data\n",
    "Predicting toxicity from molecular structures (your heavy metal work!)\n",
    "Identifying histone modification patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section1'></a>\n",
    "## 1. è®ºæ–‡æ¦‚è¿° (Paper Overview)\n",
    "\n",
    "### 1.1 ç ”ç©¶åŠ¨æœº (Motivation)\n",
    "\n",
    "**ä¸­æ–‡ï¼š**\n",
    "- æµ‹é‡ç¥ç»ç½‘ç»œç›¸ä¼¼åº¦å¯¹ç†è§£å’Œæ”¹è¿›æ·±åº¦å­¦ä¹ ç³»ç»Ÿè‡³å…³é‡è¦\n",
    "- åº”ç”¨é¢†åŸŸï¼šå­¦ä¹ åŠ¨æ€ã€æ¨¡å‹é²æ£’æ€§ã€çŸ¥è¯†è’¸é¦ã€é›†æˆå­¦ä¹ \n",
    "\n",
    "**English:**\n",
    "- Measuring similarity of neural networks is crucial for understanding and improving deep learning systems\n",
    "- Applications: learning dynamics, robustness, knowledge distillation, ensemble learning\n",
    "\n",
    "### 1.2 ä¸¤ç§äº’è¡¥è§†è§’ (Two Complementary Perspectives)\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   Neural Network f                       â”‚\n",
    "â”‚                                                          â”‚\n",
    "â”‚  Input X â†’ [Layer 1] â†’ [Layer 2] â†’ ... â†’ Output O      â”‚\n",
    "â”‚               â†“           â†“                              â”‚\n",
    "â”‚          Representation  Representation                  â”‚\n",
    "â”‚               Râ‚          Râ‚‚                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Representational Similarity: Compare Râ‚, Râ‚‚ (internal activations)\n",
    "Functional Similarity:       Compare O (outputs)\n",
    "```\n",
    "\n",
    "### 1.3 è®ºæ–‡è´¡çŒ® (Key Contributions)\n",
    "\n",
    "1. **ç³»ç»Ÿæ€§ç»¼è¿°** - 53+ ç›¸ä¼¼åº¦æµ‹é‡æ–¹æ³•\n",
    "2. **ç»Ÿä¸€æœ¯è¯­** - æ ‡å‡†åŒ–çš„æ•°å­¦å®šä¹‰\n",
    "3. **å®ç”¨æŒ‡å—** - å¦‚ä½•é€‰æ‹©å’Œåº”ç”¨è¿™äº›æ–¹æ³•\n",
    "4. **å¼€æ”¾é—®é¢˜** - æœªè§£å†³çš„ç ”ç©¶æŒ‘æˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„åº“ (Install necessary libraries)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“ (Set Chinese font)\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ (Set random seed for reproducibility)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Libraries loaded successfully!\")\n",
    "print(\"âœ… åº“åŠ è½½æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "<a id='section2'></a>\n",
    "## 2. æ ¸å¿ƒæ¦‚å¿µ (Core Concepts)\n",
    "\n",
    "### 2.1 ç¥ç»ç½‘ç»œçš„æ•°å­¦å®šä¹‰ (Mathematical Definition)\n",
    "\n",
    "**è®ºæ–‡ Equation (1):**\n",
    "\n",
    "$$f = f^{(L)} \\circ f^{(L-1)} \\circ \\cdots \\circ f^{(1)}$$\n",
    "\n",
    "å…¶ä¸­ (where):\n",
    "- $f^{(l)}: \\mathbb{R}^{D^{(l-1)}} \\rightarrow \\mathbb{R}^{D^{(l)}}$ æ˜¯ç¬¬ $l$ å±‚\n",
    "- $D^{(l)}$ æ˜¯ç¬¬ $l$ å±‚çš„ç¥ç»å…ƒæ•°é‡\n",
    "- $L$ æ˜¯æ€»å±‚æ•°\n",
    "\n",
    "### 2.2 è¡¨ç¤º (Representation)\n",
    "\n",
    "**è®ºæ–‡ Equation (2):**\n",
    "\n",
    "$$R := R^{(l)} = \\left(f^{(l)} \\circ f^{(l-1)} \\circ \\cdots \\circ f^{(1)}\\right)(X) \\in \\mathbb{R}^{N \\times D}$$\n",
    "\n",
    "å…¶ä¸­ (where):\n",
    "- $N$ = è¾“å…¥æ ·æœ¬æ•°é‡ (number of input instances)\n",
    "- $D$ = ç¥ç»å…ƒæ•°é‡ (number of neurons)\n",
    "- $R_i$ = ç¬¬ $i$ ä¸ªæ ·æœ¬çš„è¡¨ç¤º (representation of instance $i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m output_dim = \u001b[32m3\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# è¾“å…¥æ•°æ® (Input data)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m X = \u001b[43mnp\u001b[49m.random.randn(N, input_dim)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# æ¨¡å‹Açš„å‚æ•° (Model A parameters)\u001b[39;00m\n\u001b[32m     29\u001b[39m W1_A = np.random.randn(input_dim, hidden_dim) * \u001b[32m0.1\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# ç¤ºä¾‹ï¼šåˆ›å»ºç®€å•çš„ç¥ç»ç½‘ç»œè¡¨ç¤º\n",
    "# Example: Create simple neural network representations\n",
    "\n",
    "def simple_neural_network(X, W1, b1, W2, b2):\n",
    "    \"\"\"\n",
    "    ç®€å•çš„ä¸¤å±‚ç¥ç»ç½‘ç»œ\n",
    "    Simple two-layer neural network\n",
    "    \n",
    "    f(x) = W2 * ReLU(W1 * x + b1) + b2\n",
    "    \"\"\"\n",
    "    # Layer 1: ç¬¬ä¸€å±‚\n",
    "    h1 = np.maximum(0, X @ W1 + b1)  # ReLU activation\n",
    "    \n",
    "    # Layer 2: ç¬¬äºŒå±‚\n",
    "    output = h1 @ W2 + b2\n",
    "    \n",
    "    return h1, output  # è¿”å›ä¸­é—´è¡¨ç¤ºå’Œè¾“å‡º\n",
    "\n",
    "# åˆ›å»ºæ¨¡æ‹Ÿæ•°æ® (Create synthetic data)\n",
    "N = 100  # æ ·æœ¬æ•° (number of samples)\n",
    "input_dim = 10\n",
    "hidden_dim = 5\n",
    "output_dim = 3\n",
    "\n",
    "# è¾“å…¥æ•°æ® (Input data)\n",
    "X = np.random.randn(N, input_dim)\n",
    "\n",
    "# æ¨¡å‹Açš„å‚æ•° (Model A parameters)\n",
    "W1_A = np.random.randn(input_dim, hidden_dim) * 0.1\n",
    "b1_A = np.zeros(hidden_dim)\n",
    "W2_A = np.random.randn(hidden_dim, output_dim) * 0.1\n",
    "b2_A = np.zeros(output_dim)\n",
    "\n",
    "# æ¨¡å‹Bçš„å‚æ•° (Model B parameters)\n",
    "W1_B = np.random.randn(input_dim, hidden_dim) * 0.1\n",
    "b1_B = np.zeros(hidden_dim)\n",
    "W2_B = np.random.randn(hidden_dim, output_dim) * 0.1\n",
    "b2_B = np.zeros(output_dim)\n",
    "\n",
    "# è·å–è¡¨ç¤º (Get representations)\n",
    "R_A, O_A = simple_neural_network(X, W1_A, b1_A, W2_A, b2_A)\n",
    "R_B, O_B = simple_neural_network(X, W1_B, b1_B, W2_B, b2_B)\n",
    "\n",
    "print(f\"è¡¨ç¤ºç»´åº¦ (Representation shape): {R_A.shape}\")\n",
    "print(f\"è¾“å‡ºç»´åº¦ (Output shape): {O_A.shape}\")\n",
    "print(f\"\\nModel A è¡¨ç¤ºç»Ÿè®¡ (Representation statistics):\")\n",
    "print(f\"  Mean: {R_A.mean():.4f}\")\n",
    "print(f\"  Std:  {R_A.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è¡¨ç¤º (Visualize representations)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Model A representation\n",
    "im1 = axes[0].imshow(R_A.T, aspect='auto', cmap='viridis')\n",
    "axes[0].set_title('Model A Representation\\næ¨¡å‹Açš„è¡¨ç¤º', fontsize=12)\n",
    "axes[0].set_xlabel('Samples (æ ·æœ¬)')\n",
    "axes[0].set_ylabel('Neurons (ç¥ç»å…ƒ)')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Plot 2: Model B representation\n",
    "im2 = axes[1].imshow(R_B.T, aspect='auto', cmap='viridis')\n",
    "axes[1].set_title('Model B Representation\\næ¨¡å‹Bçš„è¡¨ç¤º', fontsize=12)\n",
    "axes[1].set_xlabel('Samples (æ ·æœ¬)')\n",
    "axes[1].set_ylabel('Neurons (ç¥ç»å…ƒ)')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Plot 3: Difference\n",
    "diff = np.abs(R_A - R_B)\n",
    "im3 = axes[2].imshow(diff.T, aspect='auto', cmap='Reds')\n",
    "axes[2].set_title('Absolute Difference\\nç»å¯¹å·®å¼‚', fontsize=12)\n",
    "axes[2].set_xlabel('Samples (æ ·æœ¬)')\n",
    "axes[2].set_ylabel('Neurons (ç¥ç»å…ƒ)')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"å¹³å‡å·®å¼‚ (Mean difference): {diff.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section3'></a>\n",
    "## 3. è¡¨ç¤ºç›¸ä¼¼åº¦æµ‹é‡ (Representational Similarity Measures)\n",
    "\n",
    "### 3.1 æµ‹é‡åˆ†ç±» (Categories of Measures)\n",
    "\n",
    "è®ºæ–‡å°†è¡¨ç¤ºç›¸ä¼¼åº¦æµ‹é‡åˆ†ä¸º6å¤§ç±» (The paper categorizes measures into 6 types):\n",
    "\n",
    "1. **CCA-based (åŸºäºå…¸å‹ç›¸å…³åˆ†æ)** - CCA, SVCCA, PWCCA\n",
    "2. **Alignment-based (åŸºäºå¯¹é½)** - Procrustes, Linear Regression\n",
    "3. **RSM-based (åŸºäºè¡¨ç¤ºç›¸ä¼¼æ€§çŸ©é˜µ)** - CKA, RSA, dCor\n",
    "4. **Neighbor-based (åŸºäºè¿‘é‚»)** - k-NN Jaccard\n",
    "5. **Topology-based (åŸºäºæ‹“æ‰‘)** - Geometry Score, IMD\n",
    "6. **Statistics-based (åŸºäºç»Ÿè®¡)** - Intrinsic Dimension, Magnitude\n",
    "\n",
    "### 3.2 å…³é”®æ¦‚å¿µï¼šä¸å˜æ€§ (Key Concept: Invariances)\n",
    "\n",
    "æµ‹é‡æ–¹æ³•å¯¹ä¸åŒå˜æ¢çš„ä¸å˜æ€§ (Invariance to transformations):\n",
    "\n",
    "| å˜æ¢ Transformation | ç¬¦å· Symbol | è¯´æ˜ Description |\n",
    "|-------------------|------------|------------------|\n",
    "| æ’åˆ— Permutation | PT | é‡æ’ç¥ç»å…ƒé¡ºåº Reorder neurons |\n",
    "| æ­£äº¤ Orthogonal | OT | æ—‹è½¬å’Œåå°„ Rotation & reflection |\n",
    "| ç¼©æ”¾ Isotropic Scaling | IS | ç»Ÿä¸€ç¼©æ”¾ Uniform scaling |\n",
    "| çº¿æ€§ Invertible Linear | ILT | å¯é€†çº¿æ€§å˜æ¢ Invertible linear |\n",
    "| å¹³ç§» Translation | TR | å¹³ç§» Translation |\n",
    "| ä»¿å°„ Affine | AT | ä»¿å°„å˜æ¢ Affine transformation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 é‡ç‚¹æ–¹æ³•1ï¼šCKA (Centered Kernel Alignment)\n",
    "\n",
    "**æœ€æµè¡Œçš„è¡¨ç¤ºç›¸ä¼¼åº¦æµ‹é‡æ–¹æ³•ï¼(Most popular representational similarity measure!)**\n",
    "\n",
    "**è®ºæ–‡ Equation (28):**\n",
    "\n",
    "$$m_{\\text{CKA}}(R, R') = \\frac{\\text{HSIC}(S, S')}{\\sqrt{\\text{HSIC}(S, S) \\cdot \\text{HSIC}(S', S')}}$$\n",
    "\n",
    "å…¶ä¸­ (where):\n",
    "- $S = RR^T$ (çº¿æ€§æ ¸ Linear kernel)\n",
    "- $\\text{HSIC}(S, S') = \\frac{1}{(N-1)^2} \\text{tr}(SH_NS'H_N)$\n",
    "- $H_N = I_N - \\frac{1}{N}\\mathbf{1}_N\\mathbf{1}_N^T$ (ä¸­å¿ƒåŒ–çŸ©é˜µ Centering matrix)\n",
    "\n",
    "**æ€§è´¨ (Properties):**\n",
    "- èŒƒå›´ Range: [0, 1]\n",
    "- 1 = å®Œå…¨ç›¸ä¼¼ (Perfectly similar)\n",
    "- 0 = å®Œå…¨ä¸åŒ (Completely different)\n",
    "- ä¸å˜æ€§ Invariances: æ­£äº¤å˜æ¢ + ç­‰å‘ç¼©æ”¾ (OT + IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_kernel(K):\n",
    "    \"\"\"\n",
    "    ä¸­å¿ƒåŒ–æ ¸çŸ©é˜µ\n",
    "    Center the kernel matrix\n",
    "    \"\"\"\n",
    "    N = K.shape[0]\n",
    "    H = np.eye(N) - np.ones((N, N)) / N\n",
    "    return H @ K @ H\n",
    "\n",
    "def hsic(K, L):\n",
    "    \"\"\"\n",
    "    Hilbert-Schmidt Independence Criterion\n",
    "    \"\"\"\n",
    "    N = K.shape[0]\n",
    "    K_c = center_kernel(K)\n",
    "    L_c = center_kernel(L)\n",
    "    return np.trace(K_c @ L_c) / ((N - 1) ** 2)\n",
    "\n",
    "def cka(R1, R2, kernel='linear'):\n",
    "    \"\"\"\n",
    "    è®¡ç®—CKAç›¸ä¼¼åº¦\n",
    "    Compute CKA similarity\n",
    "    \n",
    "    å‚æ•° Parameters:\n",
    "        R1, R2: è¡¨ç¤ºçŸ©é˜µ (N x D) Representation matrices\n",
    "        kernel: 'linear' or 'rbf'\n",
    "    \n",
    "    è¿”å› Returns:\n",
    "        CKA similarity score [0, 1]\n",
    "    \"\"\"\n",
    "    if kernel == 'linear':\n",
    "        K = R1 @ R1.T  # Linear kernel\n",
    "        L = R2 @ R2.T\n",
    "    elif kernel == 'rbf':\n",
    "        # RBF kernel with median heuristic\n",
    "        sigma1 = np.median(cdist(R1, R1))\n",
    "        sigma2 = np.median(cdist(R2, R2))\n",
    "        K = np.exp(-cdist(R1, R1)**2 / (2 * sigma1**2))\n",
    "        L = np.exp(-cdist(R2, R2)**2 / (2 * sigma2**2))\n",
    "    \n",
    "    hsic_kl = hsic(K, L)\n",
    "    hsic_kk = hsic(K, K)\n",
    "    hsic_ll = hsic(L, L)\n",
    "    \n",
    "    cka_score = hsic_kl / np.sqrt(hsic_kk * hsic_ll)\n",
    "    return cka_score\n",
    "\n",
    "# æµ‹è¯•CKA (Test CKA)\n",
    "print(\"=\" * 50)\n",
    "print(\"CKA Similarity Test / CKAç›¸ä¼¼åº¦æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: ç›¸åŒçš„è¡¨ç¤º (Identical representations)\n",
    "cka_identical = cka(R_A, R_A)\n",
    "print(f\"\\n1. ç›¸åŒè¡¨ç¤º (Identical): CKA = {cka_identical:.4f}\")\n",
    "\n",
    "# Test 2: ä¸åŒçš„è¡¨ç¤º (Different representations)\n",
    "cka_different = cka(R_A, R_B)\n",
    "print(f\"2. ä¸åŒè¡¨ç¤º (Different): CKA = {cka_different:.4f}\")\n",
    "\n",
    "# Test 3: æ·»åŠ å™ªå£° (Add noise)\n",
    "R_A_noisy = R_A + np.random.randn(*R_A.shape) * 0.1\n",
    "cka_noisy = cka(R_A, R_A_noisy)\n",
    "print(f\"3. æ·»åŠ å™ªå£° (With noise): CKA = {cka_noisy:.4f}\")\n",
    "\n",
    "# Test 4: æ—‹è½¬ä¸å˜æ€§ (Rotation invariance)\n",
    "Q = np.linalg.qr(np.random.randn(R_A.shape[1], R_A.shape[1]))[0]  # Random orthogonal matrix\n",
    "R_A_rotated = R_A @ Q\n",
    "cka_rotated = cka(R_A, R_A_rotated)\n",
    "print(f\"4. æ—‹è½¬å (After rotation): CKA = {cka_rotated:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… CKAå¯¹æ­£äº¤å˜æ¢ä¿æŒä¸å˜ï¼\")\n",
    "print(\"âœ… CKA is invariant to orthogonal transformations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 é‡ç‚¹æ–¹æ³•2ï¼šå…¸å‹ç›¸å…³åˆ†æ (Canonical Correlation Analysis)\n",
    "\n",
    "**è®ºæ–‡ Equation (10-12)**\n",
    "\n",
    "CCAæ‰¾åˆ°æœ€å¤§åŒ–ç›¸å…³æ€§çš„æƒé‡å‘é‡ (CCA finds weight vectors that maximize correlation):\n",
    "\n",
    "$$\\rho_i = \\max_{w_R, w_{R'}} \\frac{\\langle Rw_R, R'w_{R'} \\rangle}{\\|Rw_R\\| \\cdot \\|R'w_{R'}\\|}$$\n",
    "\n",
    "**Mean CCA:**\n",
    "$$m_{\\text{CCA}}(R, R') = \\frac{1}{D} \\sum_{i=1}^{D} \\rho_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_cca(R1, R2, n_components=None):\n",
    "    \"\"\"\n",
    "    è®¡ç®—å¹³å‡CCAç›¸ä¼¼åº¦\n",
    "    Compute mean CCA similarity\n",
    "    \"\"\"\n",
    "    if n_components is None:\n",
    "        n_components = min(R1.shape[1], R2.shape[1])\n",
    "    \n",
    "    # ä¸­å¿ƒåŒ– (Center the data)\n",
    "    R1_centered = R1 - R1.mean(axis=0)\n",
    "    R2_centered = R2 - R2.mean(axis=0)\n",
    "    \n",
    "    # ä½¿ç”¨sklearnçš„CCA (Use sklearn's CCA)\n",
    "    cca = CCA(n_components=n_components)\n",
    "    cca.fit(R1_centered, R2_centered)\n",
    "    \n",
    "    # è½¬æ¢ (Transform)\n",
    "    R1_c, R2_c = cca.transform(R1_centered, R2_centered)\n",
    "    \n",
    "    # è®¡ç®—ç›¸å…³ç³»æ•° (Compute correlations)\n",
    "    correlations = []\n",
    "    for i in range(n_components):\n",
    "        corr = np.corrcoef(R1_c[:, i], R2_c[:, i])[0, 1]\n",
    "        correlations.append(corr)\n",
    "    \n",
    "    return np.mean(correlations), correlations\n",
    "\n",
    "# è®¡ç®—CCA (Compute CCA)\n",
    "mean_cca_score, cca_correlations = mean_cca(R_A, R_B)\n",
    "\n",
    "print(f\"Mean CCA: {mean_cca_score:.4f}\")\n",
    "print(f\"\\nå„ç»´åº¦çš„å…¸å‹ç›¸å…³ç³»æ•° (Canonical correlations):\")\n",
    "for i, corr in enumerate(cca_correlations, 1):\n",
    "    print(f\"  ç»´åº¦ {i}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 é‡ç‚¹æ–¹æ³•3ï¼šProcrustesè·ç¦» (Procrustes Distance)\n",
    "\n",
    "**è®ºæ–‡ Equation (15)**\n",
    "\n",
    "å¯»æ‰¾æœ€ä¼˜æ­£äº¤å˜æ¢æ¥å¯¹é½è¡¨ç¤º (Find optimal orthogonal transformation to align representations):\n",
    "\n",
    "$$m_{\\text{Procrustes}}(R, R') = \\min_{Q \\in O(D)} \\|RQ - R'\\|_F$$\n",
    "\n",
    "å…¶ä¸­ $O(D)$ æ˜¯æ­£äº¤çŸ©é˜µç¾¤ (orthogonal group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonal_procrustes(R1, R2):\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ­£äº¤Procrustesè·ç¦»\n",
    "    Compute orthogonal Procrustes distance\n",
    "    \n",
    "    ä½¿ç”¨SVDæ±‚è§£: R1 @ Q â‰ˆ R2\n",
    "    Solve using SVD: R1 @ Q â‰ˆ R2\n",
    "    \"\"\"\n",
    "    # SVDåˆ†è§£ (SVD decomposition)\n",
    "    U, _, Vt = np.linalg.svd(R1.T @ R2)\n",
    "    \n",
    "    # æœ€ä¼˜æ­£äº¤çŸ©é˜µ (Optimal orthogonal matrix)\n",
    "    Q_opt = U @ Vt\n",
    "    \n",
    "    # è®¡ç®—è·ç¦» (Compute distance)\n",
    "    R1_aligned = R1 @ Q_opt\n",
    "    distance = np.linalg.norm(R1_aligned - R2, 'fro')\n",
    "    \n",
    "    return distance, Q_opt, R1_aligned\n",
    "\n",
    "# æµ‹è¯• (Test)\n",
    "proc_dist, Q_opt, R_A_aligned = orthogonal_procrustes(R_A, R_B)\n",
    "\n",
    "print(f\"Procrustesè·ç¦» (Procrustes distance): {proc_dist:.4f}\")\n",
    "print(f\"\\nå¯¹é½å‰çš„å·®å¼‚ (Before alignment): {np.linalg.norm(R_A - R_B, 'fro'):.4f}\")\n",
    "print(f\"å¯¹é½åçš„å·®å¼‚ (After alignment):  {np.linalg.norm(R_A_aligned - R_B, 'fro'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 æ¯”è¾ƒä¸åŒçš„ç›¸ä¼¼åº¦æµ‹é‡æ–¹æ³•\n",
    "\n",
    "è®©æˆ‘ä»¬åœ¨ä¸åŒåœºæ™¯ä¸‹æ¯”è¾ƒè¿™äº›æ–¹æ³• (Let's compare these methods in different scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¸åŒåœºæ™¯çš„è¡¨ç¤ºå¯¹ (Create representation pairs for different scenarios)\n",
    "scenarios = {\n",
    "    '1. Identical\\nç›¸åŒ': (R_A, R_A),\n",
    "    '2. Random\\néšæœº': (R_A, R_B),\n",
    "    '3. Rotated\\næ—‹è½¬': (R_A, R_A @ Q),\n",
    "    '4. Noisy\\nå™ªå£°': (R_A, R_A + np.random.randn(*R_A.shape) * 0.1),\n",
    "    '5. Scaled\\nç¼©æ”¾': (R_A, R_A * 2.0),\n",
    "}\n",
    "\n",
    "# è®¡ç®—æ‰€æœ‰æ–¹æ³•çš„ç›¸ä¼¼åº¦ (Compute similarity for all methods)\n",
    "results = []\n",
    "for name, (R1, R2) in scenarios.items():\n",
    "    cka_score = cka(R1, R2)\n",
    "    mean_cca_score, _ = mean_cca(R1, R2)\n",
    "    proc_dist, _, _ = orthogonal_procrustes(R1, R2)\n",
    "    # å½’ä¸€åŒ–Procrustesè·ç¦» (Normalize Procrustes distance)\n",
    "    proc_similarity = 1 / (1 + proc_dist)\n",
    "    \n",
    "    results.append({\n",
    "        'Scenario': name,\n",
    "        'CKA': cka_score,\n",
    "        'Mean CCA': mean_cca_score,\n",
    "        'Procrustes': proc_similarity\n",
    "    })\n",
    "\n",
    "# å¯è§†åŒ–ç»“æœ (Visualize results)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ç›¸ä¼¼åº¦æµ‹é‡æ¯”è¾ƒ (Similarity Measure Comparison)\")\n",
    "print(\"=\"*60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# ç»˜å›¾ (Plot)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(scenarios))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, df['CKA'], width, label='CKA', alpha=0.8)\n",
    "ax.bar(x, df['Mean CCA'], width, label='Mean CCA', alpha=0.8)\n",
    "ax.bar(x + width, df['Procrustes'], width, label='Procrustes (norm)', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Scenarios (åœºæ™¯)', fontsize=12)\n",
    "ax.set_ylabel('Similarity (ç›¸ä¼¼åº¦)', fontsize=12)\n",
    "ax.set_title('Comparison of Representational Similarity Measures\\nè¡¨ç¤ºç›¸ä¼¼åº¦æµ‹é‡æ–¹æ³•æ¯”è¾ƒ', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df['Scenario'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ” è§‚å¯Ÿ (Observations):\")\n",
    "print(\"  â€¢ CKAå¯¹æ—‹è½¬å’Œç¼©æ”¾ä¸å˜ (CKA is invariant to rotation and scaling)\")\n",
    "print(\"  â€¢ Procrusteså¯¹æ—‹è½¬ä¸å˜ (Procrustes is invariant to rotation)\")\n",
    "print(\"  â€¢ æ‰€æœ‰æ–¹æ³•å¯¹å™ªå£°éƒ½æ•æ„Ÿ (All methods are sensitive to noise)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section4'></a>\n",
    "## 4. å‡½æ•°ç›¸ä¼¼åº¦æµ‹é‡ (Functional Similarity Measures)\n",
    "\n",
    "å‡½æ•°ç›¸ä¼¼åº¦å…³æ³¨**æ¨¡å‹çš„è¾“å‡ºè¡Œä¸º** (Functional similarity focuses on **model output behavior**)\n",
    "\n",
    "### 4.1 æµ‹é‡åˆ†ç±» (Categories)\n",
    "\n",
    "1. **Performance-based (åŸºäºæ€§èƒ½)** - æ¯”è¾ƒå‡†ç¡®ç‡\n",
    "2. **Hard prediction-based (åŸºäºç¡¬é¢„æµ‹)** - æ¯”è¾ƒåˆ†ç±»ç»“æœ\n",
    "3. **Soft prediction-based (åŸºäºè½¯é¢„æµ‹)** - æ¯”è¾ƒæ¦‚ç‡åˆ†å¸ƒ\n",
    "4. **Gradient-based (åŸºäºæ¢¯åº¦)** - æ¯”è¾ƒæ¢¯åº¦å’Œå¯¹æŠ—æ ·æœ¬\n",
    "\n",
    "### 4.2 ä¸ä¸€è‡´åº¦ (Disagreement)\n",
    "\n",
    "**è®ºæ–‡ Equation (51)** - æœ€ç®€å•ä¸”æœ€å¸¸ç”¨çš„æ–¹æ³•\n",
    "\n",
    "$$m_{\\text{Dis}}(O, O') = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{1}\\{\\arg\\max_j O_{i,j} \\neq \\arg\\max_j O'_{i,j}\\}$$\n",
    "\n",
    "- èŒƒå›´ Range: [0, 1]\n",
    "- 0 = å®Œå…¨ä¸€è‡´ (Perfect agreement)\n",
    "- 1 = å®Œå…¨ä¸åŒ (Complete disagreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement(O1, O2):\n",
    "    \"\"\"\n",
    "    è®¡ç®—é¢„æµ‹ä¸ä¸€è‡´åº¦\n",
    "    Compute prediction disagreement\n",
    "    \n",
    "    å‚æ•° Parameters:\n",
    "        O1, O2: è¾“å‡ºçŸ©é˜µ (N x C) Output matrices\n",
    "    \n",
    "    è¿”å› Returns:\n",
    "        Disagreement rate [0, 1]\n",
    "    \"\"\"\n",
    "    pred1 = np.argmax(O1, axis=1)\n",
    "    pred2 = np.argmax(O2, axis=1)\n",
    "    return np.mean(pred1 != pred2)\n",
    "\n",
    "# åˆ›å»ºæ¨¡æ‹Ÿçš„åˆ†ç±»è¾“å‡º (Create synthetic classification outputs)\n",
    "# å‡è®¾3ç±»åˆ†ç±»é—®é¢˜ (Assume 3-class classification)\n",
    "N = 100\n",
    "C = 3\n",
    "\n",
    "# æ¨¡å‹Açš„è¾“å‡º (Model A outputs)\n",
    "logits_A = np.random.randn(N, C)\n",
    "probs_A = np.exp(logits_A) / np.exp(logits_A).sum(axis=1, keepdims=True)\n",
    "\n",
    "# æ¨¡å‹Bçš„è¾“å‡º (Model B outputs - somewhat similar to A)\n",
    "logits_B = logits_A + np.random.randn(N, C) * 0.5\n",
    "probs_B = np.exp(logits_B) / np.exp(logits_B).sum(axis=1, keepdims=True)\n",
    "\n",
    "# è®¡ç®—ä¸ä¸€è‡´åº¦ (Compute disagreement)\n",
    "dis = disagreement(probs_A, probs_B)\n",
    "print(f\"Disagreement (ä¸ä¸€è‡´åº¦): {dis:.4f}\")\n",
    "print(f\"Agreement (ä¸€è‡´åº¦): {1-dis:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Jensen-Shannonæ•£åº¦ (Jensen-Shannon Divergence)\n",
    "\n",
    "**è®ºæ–‡ Equation (60)** - æ¯”è¾ƒæ¦‚ç‡åˆ†å¸ƒ\n",
    "\n",
    "$$m_{\\text{JSD}}(O, O') = \\frac{1}{2N} \\sum_{i=1}^{N} [\\text{KL}(O_i || \\bar{O}_i) + \\text{KL}(O'_i || \\bar{O}_i)]$$\n",
    "\n",
    "å…¶ä¸­ $\\bar{O} = \\frac{O + O'}{2}$ (å¹³å‡è¾“å‡º)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q, epsilon=1e-10):\n",
    "    \"\"\"KLæ•£åº¦ (KL divergence)\"\"\"\n",
    "    p = np.clip(p, epsilon, 1)\n",
    "    q = np.clip(q, epsilon, 1)\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def jensen_shannon_divergence(O1, O2):\n",
    "    \"\"\"\n",
    "    è®¡ç®—Jensen-Shannonæ•£åº¦\n",
    "    Compute Jensen-Shannon divergence\n",
    "    \"\"\"\n",
    "    O_avg = (O1 + O2) / 2\n",
    "    jsd = 0\n",
    "    for i in range(len(O1)):\n",
    "        jsd += kl_divergence(O1[i], O_avg[i]) + kl_divergence(O2[i], O_avg[i])\n",
    "    return jsd / (2 * len(O1))\n",
    "\n",
    "# è®¡ç®—JSD (Compute JSD)\n",
    "jsd = jensen_shannon_divergence(probs_A, probs_B)\n",
    "print(f\"Jensen-Shannon Divergence: {jsd:.4f}\")\n",
    "print(f\"\\nğŸ’¡ JSD = 0 è¡¨ç¤ºå®Œå…¨ç›¸åŒ (JSD = 0 means identical)\")\n",
    "print(f\"   JSDè¶Šå¤§,åˆ†å¸ƒå·®å¼‚è¶Šå¤§ (Larger JSD means more different)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 å‡½æ•°ç›¸ä¼¼åº¦ç»¼åˆæ¯”è¾ƒ\n",
    "\n",
    "è®©æˆ‘ä»¬æ¯”è¾ƒä¸åŒçš„å‡½æ•°ç›¸ä¼¼åº¦æµ‹é‡æ–¹æ³• (Let's compare different functional similarity measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_outputs(O1, O2):\n",
    "    \"\"\"è®¡ç®—è¾“å‡ºçš„ä½™å¼¦ç›¸ä¼¼åº¦ (Compute cosine similarity of outputs)\"\"\"\n",
    "    cos_sims = []\n",
    "    for i in range(len(O1)):\n",
    "        cos_sim = np.dot(O1[i], O2[i]) / (np.linalg.norm(O1[i]) * np.linalg.norm(O2[i]))\n",
    "        cos_sims.append(cos_sim)\n",
    "    return np.mean(cos_sims)\n",
    "\n",
    "# åˆ›å»ºä¸åŒç›¸ä¼¼åº¦çš„æ¨¡å‹å¯¹ (Create model pairs with different similarities)\n",
    "scenarios_func = {\n",
    "    'Identical\\nç›¸åŒ': probs_A,\n",
    "    'Similar\\nç›¸ä¼¼': probs_A + np.random.randn(N, C) * 0.1,\n",
    "    'Moderate\\nä¸­ç­‰': probs_A + np.random.randn(N, C) * 0.5,\n",
    "    'Different\\nä¸åŒ': np.random.rand(N, C),\n",
    "}\n",
    "\n",
    "# å½’ä¸€åŒ–æ¦‚ç‡ (Normalize probabilities)\n",
    "for key in scenarios_func:\n",
    "    if key != 'Identical\\nç›¸åŒ':\n",
    "        scenarios_func[key] = np.abs(scenarios_func[key])\n",
    "        scenarios_func[key] = scenarios_func[key] / scenarios_func[key].sum(axis=1, keepdims=True)\n",
    "\n",
    "# è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ (Compute all metrics)\n",
    "results_func = []\n",
    "for name, O2 in scenarios_func.items():\n",
    "    dis = disagreement(probs_A, O2)\n",
    "    jsd = jensen_shannon_divergence(probs_A, O2)\n",
    "    cos_sim = cosine_similarity_outputs(probs_A, O2)\n",
    "    \n",
    "    results_func.append({\n",
    "        'Scenario': name,\n",
    "        'Disagreement': dis,\n",
    "        'JSD': jsd,\n",
    "        'Cos_Sim': cos_sim\n",
    "    })\n",
    "\n",
    "# æ˜¾ç¤ºç»“æœ (Display results)\n",
    "df_func = pd.DataFrame(results_func)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å‡½æ•°ç›¸ä¼¼åº¦æµ‹é‡æ¯”è¾ƒ (Functional Similarity Comparison)\")\n",
    "print(\"=\"*60)\n",
    "print(df_func.to_string(index=False))\n",
    "\n",
    "# å¯è§†åŒ– (Visualize)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Disagreement\n",
    "axes[0].bar(range(len(df_func)), df_func['Disagreement'], color='coral', alpha=0.7)\n",
    "axes[0].set_title('Disagreement\\nä¸ä¸€è‡´åº¦', fontsize=12)\n",
    "axes[0].set_xticks(range(len(df_func)))\n",
    "axes[0].set_xticklabels(df_func['Scenario'], rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# JSD\n",
    "axes[1].bar(range(len(df_func)), df_func['JSD'], color='skyblue', alpha=0.7)\n",
    "axes[1].set_title('Jensen-Shannon Divergence\\nJSDæ•£åº¦', fontsize=12)\n",
    "axes[1].set_xticks(range(len(df_func)))\n",
    "axes[1].set_xticklabels(df_func['Scenario'], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Cosine Similarity\n",
    "axes[2].bar(range(len(df_func)), df_func['Cos_Sim'], color='lightgreen', alpha=0.7)\n",
    "axes[2].set_title('Cosine Similarity\\nä½™å¼¦ç›¸ä¼¼åº¦', fontsize=12)\n",
    "axes[2].set_xticks(range(len(df_func)))\n",
    "axes[2].set_xticklabels(df_func['Scenario'], rotation=45, ha='right')\n",
    "axes[2].set_ylabel('Score')\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "axes[2].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section5'></a>\n",
    "## 5. å®Œæ•´çš„ç›¸ä¼¼åº¦åˆ†ææµç¨‹\n",
    "\n",
    "### Complete Similarity Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkSimilarity:\n",
    "    \"\"\"\n",
    "    ç¥ç»ç½‘ç»œç›¸ä¼¼åº¦åˆ†æå·¥å…·ç±»\n",
    "    Neural Network Similarity Analysis Tool\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_A, model_B, X):\n",
    "        \"\"\"\n",
    "        å‚æ•° Parameters:\n",
    "            model_A, model_B: ä¸¤ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "            X: è¾“å…¥æ•°æ®\n",
    "        \"\"\"\n",
    "        self.model_A = model_A\n",
    "        self.model_B = model_B\n",
    "        self.X = X\n",
    "        self.results = {}\n",
    "    \n",
    "    def compute_representational_similarity(self, layer='hidden'):\n",
    "        \"\"\"\n",
    "        è®¡ç®—è¡¨ç¤ºç›¸ä¼¼åº¦\n",
    "        Compute representational similarity\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"è¡¨ç¤ºç›¸ä¼¼åº¦åˆ†æ (Representational Similarity Analysis)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # æå–è¡¨ç¤º (Extract representations)\n",
    "        if layer == 'hidden':\n",
    "            R_A, _ = self.model_A(self.X)\n",
    "            R_B, _ = self.model_B(self.X)\n",
    "        \n",
    "        # è®¡ç®—å„ç§ç›¸ä¼¼åº¦ (Compute various similarities)\n",
    "        self.results['CKA'] = cka(R_A, R_B)\n",
    "        self.results['Mean_CCA'], _ = mean_cca(R_A, R_B)\n",
    "        self.results['Procrustes'], _, _ = orthogonal_procrustes(R_A, R_B)\n",
    "        \n",
    "        print(f\"\\nâœ… CKA Similarity:         {self.results['CKA']:.4f}\")\n",
    "        print(f\"âœ… Mean CCA:              {self.results['Mean_CCA']:.4f}\")\n",
    "        print(f\"âœ… Procrustes Distance:  {self.results['Procrustes']:.4f}\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def compute_functional_similarity(self):\n",
    "        \"\"\"\n",
    "        è®¡ç®—å‡½æ•°ç›¸ä¼¼åº¦\n",
    "        Compute functional similarity\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"å‡½æ•°ç›¸ä¼¼åº¦åˆ†æ (Functional Similarity Analysis)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # è·å–è¾“å‡º (Get outputs)\n",
    "        _, O_A = self.model_A(self.X)\n",
    "        _, O_B = self.model_B(self.X)\n",
    "        \n",
    "        # è½¬æ¢ä¸ºæ¦‚ç‡ (Convert to probabilities)\n",
    "        probs_A = np.exp(O_A) / np.exp(O_A).sum(axis=1, keepdims=True)\n",
    "        probs_B = np.exp(O_B) / np.exp(O_B).sum(axis=1, keepdims=True)\n",
    "        \n",
    "        # è®¡ç®—å„ç§ç›¸ä¼¼åº¦ (Compute various similarities)\n",
    "        self.results['Disagreement'] = disagreement(probs_A, probs_B)\n",
    "        self.results['JSD'] = jensen_shannon_divergence(probs_A, probs_B)\n",
    "        self.results['Cosine_Sim'] = cosine_similarity_outputs(probs_A, probs_B)\n",
    "        \n",
    "        print(f\"\\nâœ… Disagreement:         {self.results['Disagreement']:.4f}\")\n",
    "        print(f\"âœ… JSD:                  {self.results['JSD']:.4f}\")\n",
    "        print(f\"âœ… Output Cosine Sim:    {self.results['Cosine_Sim']:.4f}\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def visualize_summary(self):\n",
    "        \"\"\"\n",
    "        å¯è§†åŒ–æ€»ç»“\n",
    "        Visualize summary\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Representational similarity\n",
    "        rep_measures = ['CKA', 'Mean_CCA']\n",
    "        rep_scores = [self.results.get(m, 0) for m in rep_measures]\n",
    "        axes[0].bar(rep_measures, rep_scores, color=['#FF6B6B', '#4ECDC4'], alpha=0.8)\n",
    "        axes[0].set_title('Representational Similarity\\nè¡¨ç¤ºç›¸ä¼¼åº¦', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_ylabel('Similarity Score', fontsize=12)\n",
    "        axes[0].set_ylim([0, 1.1])\n",
    "        axes[0].grid(axis='y', alpha=0.3)\n",
    "        for i, v in enumerate(rep_scores):\n",
    "            axes[0].text(i, v + 0.05, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "        \n",
    "        # Functional similarity\n",
    "        func_measures = ['Agreement\\n(1-Dis)', 'Cosine_Sim']\n",
    "        func_scores = [1 - self.results.get('Disagreement', 0), \n",
    "                      self.results.get('Cosine_Sim', 0)]\n",
    "        axes[1].bar(func_measures, func_scores, color=['#95E1D3', '#F38181'], alpha=0.8)\n",
    "        axes[1].set_title('Functional Similarity\\nå‡½æ•°ç›¸ä¼¼åº¦', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_ylabel('Similarity Score', fontsize=12)\n",
    "        axes[1].set_ylim([0, 1.1])\n",
    "        axes[1].grid(axis='y', alpha=0.3)\n",
    "        for i, v in enumerate(func_scores):\n",
    "            axes[1].text(i, v + 0.05, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# æµ‹è¯•å®Œæ•´æµç¨‹ (Test complete pipeline)\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# å®Œæ•´çš„ç¥ç»ç½‘ç»œç›¸ä¼¼åº¦åˆ†æ (Complete NN Similarity Analysis) #\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹å‡½æ•° (Create model functions)\n",
    "def model_A_func(X):\n",
    "    return simple_neural_network(X, W1_A, b1_A, W2_A, b2_A)\n",
    "\n",
    "def model_B_func(X):\n",
    "    return simple_neural_network(X, W1_B, b1_B, W2_B, b2_B)\n",
    "\n",
    "# è¿è¡Œåˆ†æ (Run analysis)\n",
    "analyzer = NeuralNetworkSimilarity(model_A_func, model_B_func, X)\n",
    "analyzer.compute_representational_similarity()\n",
    "analyzer.compute_functional_similarity()\n",
    "analyzer.visualize_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section6'></a>\n",
    "## 6. ç”Ÿç‰©å­¦åº”ç”¨ç¤ºä¾‹ (Biological Applications)\n",
    "\n",
    "### åœºæ™¯ï¼šæ¯”è¾ƒé‡é‡‘å±æ¯’æ€§é¢„æµ‹æ¨¡å‹\n",
    "### Scenario: Comparing Heavy Metal Toxicity Prediction Models\n",
    "\n",
    "**ç ”ç©¶é—®é¢˜ (Research Question):**\n",
    "- é•‰(Cd)å’Œæ±(Hg)æ˜¯å¦é€šè¿‡ç›¸ä¼¼çš„åˆ†å­æœºåˆ¶äº§ç”Ÿæ¯’æ€§?\n",
    "- Do cadmium (Cd) and mercury (Hg) produce toxicity through similar molecular mechanisms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ‹ŸåŸºå› è¡¨è¾¾æ•°æ® (Simulate gene expression data)\n",
    "print(\"ğŸ§¬ ç”Ÿç‰©å­¦åº”ç”¨ç¤ºä¾‹ï¼šé‡é‡‘å±æ¯’æ€§ç ”ç©¶\")\n",
    "print(\"ğŸ§¬ Biological Application: Heavy Metal Toxicity Study\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æ•°æ®è®¾ç½® (Data setup)\n",
    "n_genes = 1000  # åŸºå› æ•°é‡\n",
    "n_samples = 200  # æ ·æœ¬æ•°é‡\n",
    "hidden_dim_bio = 50  # éšè—å±‚ç»´åº¦\n",
    "\n",
    "# ç”ŸæˆåŸºå› è¡¨è¾¾æ•°æ® (Generate gene expression data)\n",
    "# æ­£å¸¸æ ·æœ¬ + é•‰æš´éœ² + æ±æš´éœ²\n",
    "X_bio = np.random.lognormal(mean=5, sigma=2, size=(n_samples, n_genes))\n",
    "\n",
    "# çœŸå®æ ‡ç­¾ (True labels): 0=æ­£å¸¸, 1=ä½æ¯’, 2=é«˜æ¯’\n",
    "y_true = np.random.choice([0, 1, 2], size=n_samples, p=[0.5, 0.3, 0.2])\n",
    "\n",
    "print(f\"\\næ•°æ®ç»´åº¦ (Data dimensions):\")\n",
    "print(f\"  åŸºå› æ•° (Genes): {n_genes}\")\n",
    "print(f\"  æ ·æœ¬æ•° (Samples): {n_samples}\")\n",
    "print(f\"  ç±»åˆ«åˆ†å¸ƒ (Class distribution): {np.bincount(y_true)}\")\n",
    "\n",
    "# åˆ›å»ºä¸¤ä¸ªæ¨¡å‹ï¼šåˆ†åˆ«åœ¨Cdå’ŒHgæ•°æ®ä¸Šè®­ç»ƒ\n",
    "# Create two models: trained on Cd and Hg data respectively\n",
    "\n",
    "# æ¨¡å‹å‚æ•° (Model parameters)\n",
    "np.random.seed(42)\n",
    "W1_Cd = np.random.randn(n_genes, hidden_dim_bio) * 0.01\n",
    "b1_Cd = np.zeros(hidden_dim_bio)\n",
    "W2_Cd = np.random.randn(hidden_dim_bio, 3) * 0.01\n",
    "b2_Cd = np.zeros(3)\n",
    "\n",
    "# Hgæ¨¡å‹å‚æ•° (Hg model - somewhat similar to Cd)\n",
    "np.random.seed(43)\n",
    "W1_Hg = W1_Cd + np.random.randn(n_genes, hidden_dim_bio) * 0.005  # ç›¸ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒ\n",
    "b1_Hg = b1_Cd\n",
    "W2_Hg = W2_Cd + np.random.randn(hidden_dim_bio, 3) * 0.005\n",
    "b2_Hg = b2_Cd\n",
    "\n",
    "# è·å–è¡¨ç¤ºå’Œè¾“å‡º (Get representations and outputs)\n",
    "R_Cd, O_Cd = simple_neural_network(X_bio, W1_Cd, b1_Cd, W2_Cd, b2_Cd)\n",
    "R_Hg, O_Hg = simple_neural_network(X_bio, W1_Hg, b1_Hg, W2_Hg, b2_Hg)\n",
    "\n",
    "print(f\"\\nè¡¨ç¤ºç»´åº¦ (Representation shape): {R_Cd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ç›¸ä¼¼åº¦ (Compute similarities)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é•‰(Cd) vs æ±(Hg)æ¨¡å‹ç›¸ä¼¼åº¦åˆ†æ\")\n",
    "print(\"Cd vs Hg Model Similarity Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è¡¨ç¤ºç›¸ä¼¼åº¦ (Representational similarity)\n",
    "cka_bio = cka(R_Cd, R_Hg)\n",
    "mean_cca_bio, cca_corrs_bio = mean_cca(R_Cd, R_Hg, n_components=5)\n",
    "proc_bio, _, _ = orthogonal_procrustes(R_Cd, R_Hg)\n",
    "\n",
    "print(\"\\nğŸ”¬ è¡¨ç¤ºç›¸ä¼¼åº¦ (Representational Similarity):\")\n",
    "print(f\"  CKA:       {cka_bio:.4f}\")\n",
    "print(f\"  Mean CCA:  {mean_cca_bio:.4f}\")\n",
    "print(f\"  Procrustes: {proc_bio:.4f}\")\n",
    "\n",
    "# å‡½æ•°ç›¸ä¼¼åº¦ (Functional similarity)\n",
    "probs_Cd = np.exp(O_Cd) / np.exp(O_Cd).sum(axis=1, keepdims=True)\n",
    "probs_Hg = np.exp(O_Hg) / np.exp(O_Hg).sum(axis=1, keepdims=True)\n",
    "\n",
    "dis_bio = disagreement(probs_Cd, probs_Hg)\n",
    "jsd_bio = jensen_shannon_divergence(probs_Cd, probs_Hg)\n",
    "\n",
    "print(\"\\nğŸ¯ å‡½æ•°ç›¸ä¼¼åº¦ (Functional Similarity):\")\n",
    "print(f\"  Disagreement: {dis_bio:.4f}\")\n",
    "print(f\"  Agreement:    {1-dis_bio:.4f}\")\n",
    "print(f\"  JSD:          {jsd_bio:.4f}\")\n",
    "\n",
    "# ç”Ÿç‰©å­¦è§£é‡Š (Biological interpretation)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ” ç”Ÿç‰©å­¦è§£é‡Š (Biological Interpretation)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if cka_bio > 0.7:\n",
    "    print(\"\\nâœ… é«˜è¡¨ç¤ºç›¸ä¼¼åº¦ (CKA > 0.7):\")\n",
    "    print(\"   ä¸¤ç§é‡é‡‘å±å¯èƒ½æ¿€æ´»ç›¸ä¼¼çš„åˆ†å­é€šè·¯\")\n",
    "    print(\"   Both metals likely activate similar molecular pathways\")\n",
    "elif cka_bio > 0.4:\n",
    "    print(\"\\nâš ï¸  ä¸­ç­‰è¡¨ç¤ºç›¸ä¼¼åº¦ (0.4 < CKA < 0.7):\")\n",
    "    print(\"   éƒ¨åˆ†å…±äº«æœºåˆ¶,ä½†ä¹Ÿå­˜åœ¨ç‹¬ç‰¹çš„ä½œç”¨é€”å¾„\")\n",
    "    print(\"   Partially shared mechanisms with unique pathways\")\n",
    "else:\n",
    "    print(\"\\nâŒ ä½è¡¨ç¤ºç›¸ä¼¼åº¦ (CKA < 0.4):\")\n",
    "    print(\"   ä¸¤ç§é‡é‡‘å±é€šè¿‡ä¸åŒçš„åˆ†å­æœºåˆ¶äº§ç”Ÿæ¯’æ€§\")\n",
    "    print(\"   Different molecular mechanisms of toxicity\")\n",
    "\n",
    "if dis_bio < 0.2:\n",
    "    print(\"\\nâœ… é«˜é¢„æµ‹ä¸€è‡´æ€§ (Agreement > 0.8):\")\n",
    "    print(\"   æ¨¡å‹å¯¹æ¯’æ€§æ°´å¹³çš„åˆ¤æ–­é«˜åº¦ä¸€è‡´\")\n",
    "    print(\"   High agreement in toxicity level predictions\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  é¢„æµ‹å­˜åœ¨å·®å¼‚:\")\n",
    "    print(\"   å°½ç®¡å†…éƒ¨è¡¨ç¤ºç›¸ä¼¼,ä½†æœ€ç»ˆæ¯’æ€§è¡¨ç°å¯èƒ½ä¸åŒ\")\n",
    "    print(\"   Despite similar representations, final toxicity may differ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç”Ÿç‰©å­¦åˆ†æç»“æœ (Visualize biological analysis)\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. è¡¨ç¤ºçš„PCAå¯è§†åŒ– (PCA visualization of representations)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "pca = PCA(n_components=2)\n",
    "R_Cd_pca = pca.fit_transform(R_Cd)\n",
    "R_Hg_pca = pca.transform(R_Hg)\n",
    "\n",
    "scatter1 = ax1.scatter(R_Cd_pca[:, 0], R_Cd_pca[:, 1], \n",
    "                       c=y_true, cmap='viridis', alpha=0.6, s=50, \n",
    "                       marker='o', label='Cd Model', edgecolors='black', linewidth=0.5)\n",
    "scatter2 = ax1.scatter(R_Hg_pca[:, 0], R_Hg_pca[:, 1], \n",
    "                       c=y_true, cmap='viridis', alpha=0.6, s=50, \n",
    "                       marker='^', label='Hg Model', edgecolors='red', linewidth=0.5)\n",
    "ax1.set_xlabel('PC1', fontsize=12)\n",
    "ax1.set_ylabel('PC2', fontsize=12)\n",
    "ax1.set_title('Representation Space (PCA)\\nè¡¨ç¤ºç©ºé—´(PCAå¯è§†åŒ–)', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(alpha=0.3)\n",
    "cbar = plt.colorbar(scatter1, ax=ax1)\n",
    "cbar.set_label('Toxicity Level (æ¯’æ€§æ°´å¹³)', rotation=270, labelpad=20)\n",
    "\n",
    "# 2. ç›¸ä¼¼åº¦å¾—åˆ† (Similarity scores)\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "rep_metrics = ['CKA', 'Mean\\nCCA']\n",
    "rep_values = [cka_bio, mean_cca_bio]\n",
    "bars = ax2.bar(rep_metrics, rep_values, color=['#FF6B6B', '#4ECDC4'], alpha=0.8, edgecolor='black')\n",
    "ax2.set_ylim([0, 1.1])\n",
    "ax2.set_title('Representational\\nSimilarity\\nè¡¨ç¤ºç›¸ä¼¼åº¦', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars, rep_values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, val + 0.05, \n",
    "             f'{val:.3f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "# 3. å‡½æ•°ç›¸ä¼¼åº¦ (Functional similarity)\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "func_metrics = ['Agreement\\nä¸€è‡´åº¦', 'Output\\nCos Sim']\n",
    "func_values = [1-dis_bio, cosine_similarity_outputs(probs_Cd, probs_Hg)]\n",
    "bars = ax3.bar(func_metrics, func_values, color=['#95E1D3', '#F38181'], alpha=0.8, edgecolor='black')\n",
    "ax3.set_ylim([0, 1.1])\n",
    "ax3.set_title('Functional\\nSimilarity\\nå‡½æ•°ç›¸ä¼¼åº¦', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars, func_values):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, val + 0.05, \n",
    "             f'{val:.3f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "# 4. å…¸å‹ç›¸å…³ç³»æ•° (Canonical correlations)\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "ax4.plot(range(1, len(cca_corrs_bio)+1), cca_corrs_bio, \n",
    "         'o-', color='purple', linewidth=2, markersize=8)\n",
    "ax4.set_xlabel('Component', fontsize=11)\n",
    "ax4.set_ylabel('Correlation', fontsize=11)\n",
    "ax4.set_title('Canonical\\nCorrelations\\nå…¸å‹ç›¸å…³ç³»æ•°', fontsize=11, fontweight='bold')\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.set_ylim([0, 1.1])\n",
    "\n",
    "# 5. é¢„æµ‹åˆ†å¸ƒæ¯”è¾ƒ (Prediction distribution comparison)\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "pred_Cd = np.argmax(probs_Cd, axis=1)\n",
    "pred_Hg = np.argmax(probs_Hg, axis=1)\n",
    "\n",
    "# æ··æ·†çŸ©é˜µå¯è§†åŒ– (Confusion matrix visualization)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(pred_Cd, pred_Hg)\n",
    "im = ax5.imshow(cm, cmap='YlOrRd', aspect='auto')\n",
    "ax5.set_xlabel('Hg Model Prediction (æ±æ¨¡å‹é¢„æµ‹)', fontsize=12)\n",
    "ax5.set_ylabel('Cd Model Prediction (é•‰æ¨¡å‹é¢„æµ‹)', fontsize=12)\n",
    "ax5.set_title('Prediction Agreement Matrix\\né¢„æµ‹ä¸€è‡´æ€§çŸ©é˜µ', fontsize=13, fontweight='bold')\n",
    "ax5.set_xticks([0, 1, 2])\n",
    "ax5.set_yticks([0, 1, 2])\n",
    "ax5.set_xticklabels(['Normal\\næ­£å¸¸', 'Low Tox\\nä½æ¯’', 'High Tox\\né«˜æ¯’'])\n",
    "ax5.set_yticklabels(['Normal\\næ­£å¸¸', 'Low Tox\\nä½æ¯’', 'High Tox\\né«˜æ¯’'])\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾ (Add numerical labels)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        text = ax5.text(j, i, cm[i, j], ha=\"center\", va=\"center\", \n",
    "                       color=\"white\" if cm[i, j] > cm.max()/2 else \"black\",\n",
    "                       fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=ax5, label='Sample Count (æ ·æœ¬æ•°)')\n",
    "\n",
    "plt.suptitle('Cd vs Hg Toxicity Model Comparison\\né•‰ vs æ±æ¯’æ€§æ¨¡å‹ç»¼åˆæ¯”è¾ƒ', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… å¯è§†åŒ–å®Œæˆï¼ (Visualization complete!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section7'></a>\n",
    "## 7. æ€»ç»“ä¸å…³é”®è¦ç‚¹ (Summary & Key Takeaways)\n",
    "\n",
    "### 7.1 æµ‹é‡æ–¹æ³•é€‰æ‹©æŒ‡å— (Guide for Selecting Measures)\n",
    "\n",
    "#### è¡¨ç¤ºç›¸ä¼¼åº¦ (Representational Similarity):\n",
    "\n",
    "| æ–¹æ³• Method | ä¼˜ç‚¹ Advantages | ç¼ºç‚¹ Disadvantages | æ¨èåœºæ™¯ Recommended Use |\n",
    "|------------|----------------|-------------------|-------------------------|\n",
    "| **CKA** | â€¢ æœ€æµè¡Œ<br>â€¢ å¯¹æ—‹è½¬/ç¼©æ”¾ä¸å˜<br>â€¢ èŒƒå›´[0,1]æ˜“è§£é‡Š | â€¢ å¯¹å•ä¸ªæ ·æœ¬æ”¹å˜æ•æ„Ÿ<br>â€¢ è®¡ç®—å¤æ‚åº¦O(NÂ²) | â€¢ ä¸€èˆ¬ç”¨é€”<br>â€¢ æ¯”è¾ƒä¸åŒæ¶æ„<br>â€¢ å±‚çº§æ¯”è¾ƒ |\n",
    "| **CCA** | â€¢ è€ƒè™‘çº¿æ€§å…³ç³»<br>â€¢ ç»´åº¦è‡ªé€‚åº” | â€¢ éœ€è¦Dâ‰¥N<br>â€¢ å¯¹å™ªå£°æ•æ„Ÿ | â€¢ é«˜ç»´è¡¨ç¤º<br>â€¢ æ‰¾åˆ°å¯¹åº”å…³ç³» |\n",
    "| **Procrustes** | â€¢ å‡ ä½•ç›´è§‚<br>â€¢ æ»¡è¶³è·ç¦»åº¦é‡ | â€¢ éœ€è¦ç›¸åŒç»´åº¦<br>â€¢ ä»…æ­£äº¤å˜æ¢ | â€¢ åŒæ¶æ„æ¨¡å‹<br>â€¢ éœ€è¦å‡ ä½•è§£é‡Š |\n",
    "\n",
    "#### å‡½æ•°ç›¸ä¼¼åº¦ (Functional Similarity):\n",
    "\n",
    "| æ–¹æ³• Method | é€‚ç”¨åœºæ™¯ Use Case | æ³¨æ„äº‹é¡¹ Notes |\n",
    "|------------|------------------|---------------|\n",
    "| **Disagreement** | å¿«é€Ÿæ¯”è¾ƒ | å—å‡†ç¡®ç‡å½±å“ |\n",
    "| **JSD** | æ¦‚ç‡åˆ†å¸ƒæ¯”è¾ƒ | è€ƒè™‘é¢„æµ‹ç½®ä¿¡åº¦ |\n",
    "| **Gradient-based** | æ·±å…¥åˆ†æå†³ç­–è¾¹ç•Œ | éœ€è¦ç™½ç›’è®¿é—® |\n",
    "\n",
    "### 7.2 å®è·µå»ºè®® (Practical Recommendations)\n",
    "\n",
    "**âœ… æ¨èåšæ³• (Recommended Practices):**\n",
    "1. åŒæ—¶ä½¿ç”¨è¡¨ç¤ºå’Œå‡½æ•°ç›¸ä¼¼åº¦ (Use both representational and functional similarity)\n",
    "2. ä½¿ç”¨å¤šä¸ªæµ‹é‡æ–¹æ³•äº¤å‰éªŒè¯ (Use multiple measures for cross-validation)\n",
    "3. è€ƒè™‘æ•°æ®çš„ç»Ÿè®¡ç‰¹æ€§ (Consider statistical properties of data)\n",
    "4. æŠ¥å‘Šç½®ä¿¡åŒºé—´ (Report confidence intervals)\n",
    "\n",
    "**âŒ é¿å…åšæ³• (Practices to Avoid):**\n",
    "1. ä»…ç”¨å•ä¸€æµ‹é‡æ–¹æ³• (Relying on a single measure)\n",
    "2. å¿½ç•¥ä¸å˜æ€§å‡è®¾ (Ignoring invariance assumptions)\n",
    "3. åœ¨å°æ ·æœ¬ä¸Šä¸‹ç»“è®º (Drawing conclusions from small samples)\n",
    "\n",
    "### 7.3 æœªæ¥ç ”ç©¶æ–¹å‘ (Future Research Directions)\n",
    "\n",
    "è®ºæ–‡æŒ‡å‡ºçš„å¼€æ”¾é—®é¢˜ (Open challenges identified in the paper):\n",
    "\n",
    "1. **å¯è§£é‡Šæ€§ (Interpretability)**\n",
    "   - å¦‚ä½•è§£é‡Šç›¸ä¼¼åº¦åˆ†æ•°çš„ç”Ÿç‰©å­¦æ„ä¹‰?\n",
    "   - How to interpret similarity scores biologically?\n",
    "\n",
    "2. **é²æ£’æ€§ (Robustness)**\n",
    "   - å¦‚ä½•ä½¿æµ‹é‡å¯¹å™ªå£°å’Œå¼‚å¸¸å€¼æ›´é²æ£’?\n",
    "   - How to make measures more robust to noise?\n",
    "\n",
    "3. **è®¡ç®—æ•ˆç‡ (Computational Efficiency)**\n",
    "   - å¦‚ä½•åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šé«˜æ•ˆè®¡ç®—?\n",
    "   - How to compute efficiently on large-scale data?\n",
    "\n",
    "4. **ç†è®ºä¿è¯ (Theoretical Guarantees)**\n",
    "   - ä»€ä¹ˆæ—¶å€™é«˜è¡¨ç¤ºç›¸ä¼¼åº¦æ„å‘³ç€é«˜å‡½æ•°ç›¸ä¼¼åº¦?\n",
    "   - When does high representational similarity imply functional similarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 ä½ çš„ç ”ç©¶ä¸­çš„åº”ç”¨ (Applications in Your Research)\n",
    "\n",
    "**å¯¹ä½ çš„æ¯’ç†å­¦å’Œç»„è›‹ç™½ç ”ç©¶çš„å¯ç¤º (Implications for toxicology and histone research):**\n",
    "\n",
    "1. **æ¯”è¾ƒä¸åŒæ¯’ç‰©çš„ä½œç”¨æœºåˆ¶**\n",
    "   - ä½¿ç”¨è¡¨ç¤ºç›¸ä¼¼åº¦åˆ¤æ–­æ˜¯å¦å…±äº«åˆ†å­é€šè·¯\n",
    "   - Use representational similarity to determine shared pathways\n",
    "\n",
    "2. **éªŒè¯æ¨¡å‹çš„ç”Ÿç‰©å­¦åˆç†æ€§**\n",
    "   - æ£€æŸ¥æ¨¡å‹å­¦åˆ°çš„ç‰¹å¾æ˜¯å¦ä¸å·²çŸ¥ç”Ÿç‰©å­¦ä¸€è‡´\n",
    "   - Check if learned features align with known biology\n",
    "\n",
    "3. **è¿ç§»å­¦ä¹ çš„å¯è¡Œæ€§**\n",
    "   - é«˜ç›¸ä¼¼åº¦è¡¨æ˜å¯ä»¥è¿ç§»çŸ¥è¯†\n",
    "   - High similarity suggests knowledge transfer is feasible\n",
    "\n",
    "4. **å‘ç°æ–°çš„ç”Ÿç‰©å­¦å…³è”**\n",
    "   - æ„å¤–çš„é«˜ç›¸ä¼¼åº¦å¯èƒ½æ­ç¤ºæœªçŸ¥è”ç³»\n",
    "   - Unexpected high similarity may reveal unknown connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“š å‚è€ƒèµ„æº (References)\n",
    "\n",
    "### ä¸»è¦è®ºæ–‡ (Main Paper):\n",
    "Klabunde, M., Schumacher, T., Strohmaier, M., & Lemmerich, F. (2025). \n",
    "Similarity of Neural Network Models: A Survey of Functional and Representational Measures. \n",
    "*ACM Computing Surveys*, 57(9), Article 242.\n",
    "\n",
    "### ç›¸å…³å·¥å…·å’Œåº“ (Related Tools & Libraries):\n",
    "- **ReSi Benchmark**: https://github.com/mklabunde/resi\n",
    "- **Similarity Repository**: https://github.com/nacloos/similarity-repository\n",
    "- **CKA Implementation**: Various implementations in PyTorch/TensorFlow\n",
    "\n",
    "### æ‰©å±•é˜…è¯» (Further Reading):\n",
    "1. Kornblith et al. (2019) - CKAåŸå§‹è®ºæ–‡ (Original CKA paper)\n",
    "2. Raghu et al. (2017) - SVCCA\n",
    "3. Morcos et al. (2018) - PWCCA\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ ç»ƒä¹ å’Œæ€è€ƒé¢˜ (Exercises & Questions)\n",
    "\n",
    "1. **ä¸ºä»€ä¹ˆCKAå¯¹æ­£äº¤å˜æ¢ä¸å˜,è€ŒEuclideanè·ç¦»ä¸æ˜¯?**\n",
    "   - Why is CKA invariant to orthogonal transformations but Euclidean distance is not?\n",
    "\n",
    "2. **åœ¨ä»€ä¹ˆæƒ…å†µä¸‹,ä¸¤ä¸ªæ¨¡å‹çš„è¡¨ç¤ºç›¸ä¼¼ä½†è¾“å‡ºä¸åŒ?**\n",
    "   - When can two models have similar representations but different outputs?\n",
    "\n",
    "3. **å¦‚ä½•ä¸ºä½ çš„RNA-seqæ•°æ®é€‰æ‹©åˆé€‚çš„ç›¸ä¼¼åº¦æµ‹é‡?**\n",
    "   - How would you choose appropriate similarity measures for RNA-seq data?\n",
    "\n",
    "4. **å°è¯•ä¿®æ”¹ä»£ç ,æ·»åŠ ä½ è‡ªå·±çš„æ•°æ®!**\n",
    "   - Try modifying the code to add your own data!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ä¸‹ä¸€æ­¥ (Next Steps)\n",
    "\n",
    "1. é˜…è¯»å®Œæ•´è®ºæ–‡äº†è§£æ›´å¤šç»†èŠ‚\n",
    "2. åœ¨ä½ çš„å®é™…æ•°æ®ä¸Šæµ‹è¯•è¿™äº›æ–¹æ³•\n",
    "3. æ¢ç´¢ReSi benchmark\n",
    "4. è€ƒè™‘å¦‚ä½•å°†è¿™äº›æ–¹æ³•åº”ç”¨åˆ°ä½ çš„æ¯’ç†å­¦ç ”ç©¶ä¸­\n",
    "\n",
    "---\n",
    "\n",
    "**Created by:** YueYueYYY  \n",
    "**Date:** December 2025  \n",
    "**Based on:** Klabunde et al. (2025) ACM Computing Surveys\n",
    "\n",
    "**ç¥å­¦ä¹ æ„‰å¿«! Happy Learning! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
